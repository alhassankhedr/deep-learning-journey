{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa0d4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adafactor',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'NAdam',\n",
       " 'Optimizer',\n",
       " 'RAdam',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_adafactor',\n",
       " '_functional',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e75a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad= True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b351111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "t_un = 0.1 * t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5139f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3728e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch}, Loss {float(loss)}')\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ce4ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.612898349761963\n",
      "Epoch 1000, Loss 3.0866994857788086\n",
      "Epoch 1500, Loss 2.928579807281494\n",
      "Epoch 2000, Loss 2.9276442527770996\n",
      "Epoch 2500, Loss 2.927645683288574\n",
      "Epoch 3000, Loss 2.9276459217071533\n",
      "Epoch 3500, Loss 2.927644968032837\n",
      "Epoch 4000, Loss 2.927645683288574\n",
      "Epoch 4500, Loss 2.927645206451416\n",
      "Epoch 5000, Loss 2.927645206451416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.5368, -17.3048], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad= True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=5000,\n",
    "    optimizer= optimizer,\n",
    "    params= params,\n",
    "    t_u= t_u,\n",
    "    t_c= t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27100ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 9,  5,  0, 10,  4,  3,  6,  8,  7]), tensor([1, 2]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b584be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "train_t_un = 0.1 * train_t_u\n",
    "val_t_un = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48099f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(t_u, w1, w2, b):\n",
    "    return w2 * t_u**2 + w1 * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86119c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model2(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_t_p = model2(val_t_u, *params)\n",
    "            val_loss = loss_fn(val_t_p, val_t_c)\n",
    "            assert val_loss.requires_grad == False\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch}, Training Loss {train_loss.item():.4f},'\n",
    "                  f' Validation loss {val_loss.item():.4f}')\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16aff61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss 700.2715, Validation loss 565.6469\n",
      "Epoch 2, Training Loss 668.1007, Validation loss 537.6002\n",
      "Epoch 3, Training Loss 637.4429, Validation loss 510.9091\n",
      "Epoch 500, Training Loss 15.8082, Validation loss 1.7930\n",
      "Epoch 1000, Training Loss 15.2907, Validation loss 1.8957\n",
      "Epoch 1500, Training Loss 14.7932, Validation loss 1.9989\n",
      "Epoch 2000, Training Loss 14.3149, Validation loss 2.1028\n",
      "Epoch 2500, Training Loss 13.8552, Validation loss 2.2072\n",
      "Epoch 3000, Training Loss 13.4133, Validation loss 2.3122\n",
      "Epoch 3500, Training Loss 12.9885, Validation loss 2.4174\n",
      "Epoch 4000, Training Loss 12.5802, Validation loss 2.5230\n",
      "Epoch 4500, Training Loss 12.1876, Validation loss 2.6287\n",
      "Epoch 5000, Training Loss 11.8103, Validation loss 2.7345\n",
      "Epoch 5500, Training Loss 11.4476, Validation loss 2.8402\n",
      "Epoch 6000, Training Loss 11.0989, Validation loss 2.9459\n",
      "Epoch 6500, Training Loss 10.7637, Validation loss 3.0514\n",
      "Epoch 7000, Training Loss 10.4415, Validation loss 3.1567\n",
      "Epoch 7500, Training Loss 10.1318, Validation loss 3.2616\n",
      "Epoch 8000, Training Loss 9.8341, Validation loss 3.3662\n",
      "Epoch 8500, Training Loss 9.5479, Validation loss 3.4704\n",
      "Epoch 9000, Training Loss 9.2727, Validation loss 3.5741\n",
      "Epoch 9500, Training Loss 9.0083, Validation loss 3.6772\n",
      "Epoch 10000, Training Loss 8.7540, Validation loss 3.7798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1014,  0.3790, -0.3619], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=10000,\n",
    "    optimizer=optimizer,\n",
    "    params=params,\n",
    "    train_t_u=train_t_un,\n",
    "    val_t_u=val_t_un,\n",
    "    train_t_c=train_t_c,\n",
    "    val_t_c=val_t_c\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
